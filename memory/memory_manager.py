# memory_manager.py
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import uuid
from datetime import datetime
from typing import List, Dict, Optional
import requests
from core.language_utils import LanguageDetector
import json

class MemoryManager:
    def __init__(self, persist_dir="./memory_db", collection_name="assistant_memory"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏"""
        # –í–µ–∫—Ç–æ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (384 –∏–∑–º–µ—Ä–µ–Ω–∏—è, –±—ã—Å—Ç—Ä–∞—è)
        self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        try:
            self.lang_detector = LanguageDetector()
        except:
            self.lang_detector = None

        # –û–±–Ω–æ–≤–∏—Ç–µ –º–µ—Ç–æ–¥ add_memory (–¥–æ–±–∞–≤—å—Ç–µ —Ç–æ–ª—å–∫–æ 2 —Å—Ç—Ä–æ–∫–∏):
        def add_memory(self, content: str, memory_type: str = "user_info",
                       metadata: Optional[Dict] = None) -> str:
            memory_id = str(uuid.uuid4())
            embedding = self.embedder.encode(content).tolist()

            # –ù–û–í–û–ï: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫
            detected_lang = self.lang_detector.detect(content) if self.lang_detector else 'unknown'

            mem_metadata = {
                "type": memory_type,
                "language": detected_lang,  # –ù–û–í–û–ï
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }

            if metadata:
                mem_metadata.update(metadata)

            self.collection.add(
                ids=[memory_id],
                documents=[content],
                embeddings=[embedding],
                metadatas=[mem_metadata]
            )

            return memory_id

        # –û–±–Ω–æ–≤–∏—Ç–µ update_memory (–¥–æ–±–∞–≤—å—Ç–µ 1 —Å—Ç—Ä–æ–∫—É):
        def update_memory(self, memory_id: str, new_content: str, new_metadata: Optional[Dict] = None):
            old = self.collection.get(ids=[memory_id])
            if not old['ids']:
                print(f"‚ùå –ü–∞–º—è—Ç—å {memory_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return

            metadata = old['metadatas'][0]
            metadata['updated_at'] = datetime.now().isoformat()
            metadata['language'] = self.lang_detector.detect(new_content) if self.lang_detector else 'unknown'  # –ù–û–í–û–ï

            if new_metadata:
                metadata.update(new_metadata)

            embedding = self.embedder.encode(new_content).tolist()
            self.collection.update(
                ids=[memory_id],
                documents=[new_content],
                embeddings=[embedding],
                metadatas=[metadata]
            )
            print(f"‚úÖ –ü–∞–º—è—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {memory_id[:8]}...")


        # ChromaDB –∫–ª–∏–µ–Ω—Ç —Å –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º —Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
        self.client = chromadb.PersistentClient(
            path=persist_dir,
            settings=Settings(anonymized_telemetry=False)
        )

        # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}  # –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞
        )

    def add_memory(self, content: str, memory_type: str = "user_info",
                   metadata: Optional[Dict] = None) -> str:
        """–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –≤ –ø–∞–º—è—Ç—å"""
        memory_id = str(uuid.uuid4())

        embedding = self.embedder.encode(content).tolist()

        mem_metadata = {
            "type": memory_type,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        if metadata:
            mem_metadata.update(metadata)

        self.collection.add(
            ids=[memory_id],
            documents=[content],
            embeddings=[embedding],
            metadatas=[mem_metadata]
        )

        # –£–±—Ä–∞–ª–∏ print
        return memory_id

    def search_memory(self, query: str, top_k: int = 10,
                      memory_type: Optional[str] = None) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            memory_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –ø–∞–º—è—Ç–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
        """
        # –°–æ–∑–¥–∞—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embedder.encode(query).tolist()

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä
        where_filter = {"type": memory_type} if memory_type else None

        # –ü–æ–∏—Å–∫
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=where_filter,
            include=["documents", "metadatas", "distances"]
        )

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        memories = []
        if results['ids']:
            for i, doc_id in enumerate(results['ids'][0]):
                memories.append({
                    "id": doc_id,
                    "content": results['documents'][0][i],
                    "metadata": results['metadatas'][0][i],
                    "relevance": 1 - results['distances'][0][i]  # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                })

        return memories

    def update_memory(self, memory_id: str, new_content: str,
                      new_metadata: Optional[Dict] = None):
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å

        Args:
            memory_id: ID –∑–∞–ø–∏—Å–∏ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            new_content: –ù–æ–≤—ã–π —Ç–µ–∫—Å—Ç
            new_metadata: –ù–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        """
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å
        old = self.collection.get(ids=[memory_id])
        if not old['ids']:
            print(f"‚ùå –ü–∞–º—è—Ç—å {memory_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = old['metadatas'][0]
        metadata['updated_at'] = datetime.now().isoformat()
        if new_metadata:
            metadata.update(new_metadata)

        # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥
        embedding = self.embedder.encode(new_content).tolist()

        # –û–±–Ω–æ–≤–ª—è–µ–º
        self.collection.update(
            ids=[memory_id],
            documents=[new_content],
            embeddings=[embedding],
            metadatas=[metadata]
        )

        print(f"‚úÖ –ü–∞–º—è—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {memory_id[:8]}...")

    def delete_memory(self, memory_id: str):
        """–£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å—å –∏–∑ –ø–∞–º—è—Ç–∏"""
        self.collection.delete(ids=[memory_id])
        print(f"üóëÔ∏è –ü–∞–º—è—Ç—å —É–¥–∞–ª–µ–Ω–∞: {memory_id[:8]}...")

    def list_all_memories(self, memory_type: Optional[str] = None) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ –≤ –ø–∞–º—è—Ç–∏

        Args:
            memory_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É

        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
        """
        where_filter = {"type": memory_type} if memory_type else None

        results = self.collection.get(
            where=where_filter,
            include=["documents", "metadatas"]
        )

        memories = []
        if results['ids']:
            for i, doc_id in enumerate(results['ids']):
                memories.append({
                    "id": doc_id,
                    "content": results['documents'][i],
                    "metadata": results['metadatas'][i]
                })

        return memories

    def clear_all_memories(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –≤—Å—é –ø–∞–º—è—Ç—å (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ!)"""
        # –£–¥–∞–ª—è–µ–º –∏ —Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –∑–∞–Ω–æ–≤–æ
        self.client.delete_collection(name=self.collection.name)
        self.collection = self.client.get_or_create_collection(
            name=self.collection.name,
            metadata={"hnsw:space": "cosine"}
        )
        print("üóëÔ∏è –í—Å—è –ø–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")

    def extract_important_info(self, conversation_text: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
        (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é LLM)

        Args:
            conversation_text: –¢–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞

        Returns:
            –í–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–ª–∏ None
        """
        # –ü—Ä–æ—Å—Ç—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        important_keywords = [
            "–º–µ–Ω—è –∑–æ–≤—É—Ç", "—è —Ä–∞–±–æ—Ç–∞—é", "—è –ª—é–±–ª—é", "–º–æ–π –ª—é–±–∏–º—ã–π",
            "—è –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é", "–∑–∞–ø–æ–º–Ω–∏", "–≤–∞–∂–Ω–æ", "–≤—Å–µ–≥–¥–∞ –¥–µ–ª–∞–π",
            "–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ", "–º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è", "—è –Ω–µ –ª—é–±–ª—é"
        ]

        text_lower = conversation_text.lower()
        for keyword in important_keywords:
            if keyword in text_lower:
                return conversation_text

        return None

    # memory_manager.py - –¥–æ–±–∞–≤—å —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤ –∫–ª–∞—Å—Å MemoryManager



    def extract_with_llm(self, user_message: str, assistant_response: str,
                         llm_url: str, llm_model: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é LLM

        Args:
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            assistant_response: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            llm_url: URL –≤–∞—à–µ–π Ollama
            llm_model: –ú–æ–¥–µ–ª—å (gemma3:4b)

        Returns:
            –°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
        """
        extraction_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥ –∏ –∏–∑–≤–ª–µ–∫–∏ –¢–û–õ–¨–ö–û –≤–∞–∂–Ω—ã–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ.

    –•–û–†–û–®–ò–ï –ø—Ä–∏–º–µ—Ä—ã (–∏–∑–≤–ª–µ–∫–∞–π):
    - "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω—Ä–∞–≤—è—Ç—Å—è –∫–æ—à–∫–∏"
    - "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º"
    - "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç —á–∞–π –∫–æ—Ñ–µ"
    - "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∂–∏–≤—ë—Ç –≤ –ú–æ—Å–∫–≤–µ"
    - "–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∞–ª–ª–µ—Ä–≥–∏—è –Ω–∞ –æ—Ä–µ—Ö–∏"

    –ü–õ–û–•–ò–ï –ø—Ä–∏–º–µ—Ä—ã (–ù–ï –∏–∑–≤–ª–µ–∫–∞–π):
    - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã ("–∫–∞–∫–∞—è –ø–æ–≥–æ–¥–∞")
    - –¢–µ–∫—É—â–∏–µ –∫–æ–º–∞–Ω–¥—ã ("–≤–∫–ª—é—á–∏ –º—É–∑—ã–∫—É")
    - –û–±—â–∏–µ —Ç–µ–º—ã –±–µ–∑ –ª–∏—á–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π

    –î–∏–∞–ª–æ–≥:
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}
    –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {assistant_response}

    –í—ã–≤–µ–¥–∏ 1-3 –≤–∞–∂–Ω—ã—Ö —Ñ–∞–∫—Ç–∞ (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏) –∏–ª–∏ –Ω–∞–ø–∏—à–∏ "–ù–ï–¢" –µ—Å–ª–∏ —Ñ–∞–∫—Ç–æ–≤ –Ω–µ—Ç.
    –§–æ—Ä–º–∞—Ç: –∫—Ä–∞—Ç–∫–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤."""



        payload = {
            "model": llm_model,
            "prompt": extraction_prompt,
            "stream": False
        }

        try:
            response = requests.post(llm_url, json=payload, timeout=30)
            if response.status_code == 200:
                result = response.json()
                facts_text = result.get("response", "").strip()

                if facts_text and facts_text.upper() != "–ù–ï–¢":
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã
                    facts = [f.strip() for f in facts_text.split('\n') if f.strip()]
                    # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é —Ç–∏–ø–∞ "1.", "2."
                    facts = [f.lstrip('0123456789.-) ') for f in facts]
                    return facts[:3]  # –º–∞–∫—Å–∏–º—É–º 3 —Ñ–∞–∫—Ç–∞
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")

        return []

    def manage_memory_conflicts(self, new_fact: str, llm_url: str, llm_model: str) -> str:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è —Å–æ —Å—Ç–∞—Ä—ã–º–∏ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ

        Args:
            new_fact: –ù–æ–≤—ã–π —Ñ–∞–∫—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            llm_url: URL Ollama
            llm_model: –ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –î–µ–π—Å—Ç–≤–∏–µ: "add" (–¥–æ–±–∞–≤–∏—Ç—å), "update" (–æ–±–Ω–æ–≤–∏—Ç—å), "skip" (–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å)
        """
        import requests
        import json

        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è
        similar_memories = self.search_memory(new_fact, top_k=3)

        if not similar_memories or similar_memories[0]['relevance'] < 0.7:
            # –ù–µ—Ç –ø–æ—Ö–æ–∂–∏—Ö - –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º
            return {"action": "add", "memory_id": None}

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç–∞—Ä—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
        old_facts_text = "\n".join([
            f"ID: {mem['id'][:8]}... | {mem['content']}"
            for mem in similar_memories if mem['relevance'] > 0.7
        ])

        # –ü—Ä–æ—Å–∏–º LLM –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç
        analysis_prompt = f"""–¢—ã —É–ø—Ä–∞–≤–ª—è–µ—à—å –ø–∞–º—è—Ç—å—é –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤—ã–π —Ñ–∞–∫—Ç –∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è.

    –°–£–©–ï–°–¢–í–£–Æ–©–ò–ï –í–û–°–ü–û–ú–ò–ù–ê–ù–ò–Ø:
    {old_facts_text}

    –ù–û–í–´–ô –§–ê–ö–¢:
    {new_fact}

    –ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏, —á—Ç–æ –¥–µ–ª–∞—Ç—å —Å –Ω–æ–≤—ã–º —Ñ–∞–∫—Ç–æ–º.

    –í–ê–†–ò–ê–ù–¢–´:
    1. ADD - –µ—Å–ª–∏ –Ω–æ–≤—ã–π —Ñ–∞–∫—Ç –¥–æ–ø–æ–ª–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (–Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç —Å—Ç–∞—Ä—ã–º)
    2. UPDATE - –µ—Å–ª–∏ –Ω–æ–≤—ã–π —Ñ–∞–∫—Ç –æ–±–Ω–æ–≤–ª—è–µ—Ç/–∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, "—Ä–∞–Ω—å—à–µ –ª—é–±–∏–ª –∫–æ—Ñ–µ, —Ç–µ–ø–µ—Ä—å –ª—é–±–ª—é —á–∞–π")
    3. SKIP - –µ—Å–ª–∏ —Ñ–∞–∫—Ç —É–∂–µ –µ—Å—Ç—å –≤ –ø–∞–º—è—Ç–∏ (–ø–æ–ª–Ω—ã–π –¥—É–±–ª–∏–∫–∞—Ç)

    –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
    {{
      "action": "ADD/UPDATE/SKIP",
      "reason": "–∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞",
      "update_id": "–ø–µ—Ä–≤—ã–µ 8 —Å–∏–º–≤–æ–ª–æ–≤ ID –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–µ—Å–ª–∏ UPDATE) –∏–ª–∏ null"
    }}"""

        payload = {
            "model": llm_model,
            "prompt": analysis_prompt,
            "stream": False
        }

        try:
            response = requests.post(llm_url, json=payload, timeout=30)
            if response.status_code == 200:
                result_text = response.json().get("response", "").strip()

                # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
                import re
                json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                if json_match:
                    decision = json.loads(json_match.group())

                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–ª–Ω—ã–π ID –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
                    if decision['action'] == 'UPDATE' and decision.get('update_id'):
                        short_id = decision['update_id']
                        for mem in similar_memories:
                            if mem['id'].startswith(short_id):
                                decision['memory_id'] = mem['id']
                                break

                    return decision
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞: {e}")

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –¥–æ–±–∞–≤–ª—è–µ–º
        return {"action": "add", "memory_id": None, "reason": "–æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"}

    def auto_deduplicate(self, llm_url: str, llm_model: str):
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
        """
        import requests
        import json

        all_memories = self.list_all_memories()

        if len(all_memories) < 2:
            return

        print("üîç –ò—â—É –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –ø–∞–º—è—Ç–∏...")

        processed_ids = set()

        for i, mem1 in enumerate(all_memories):
            if mem1['id'] in processed_ids:
                continue

            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ
            similar = self.search_memory(mem1['content'], top_k=5)
            duplicates = [
                s for s in similar
                if s['id'] != mem1['id']
                   and s['relevance'] > 0.85  # –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–µ
                   and s['id'] not in processed_ids
            ]

            if not duplicates:
                continue

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
            to_merge = [mem1] + [d for d in all_memories if d['id'] in [dup['id'] for dup in duplicates]]
            merge_text = "\n".join([f"- {m['content']}" for m in to_merge])

            # –ü—Ä–æ—Å–∏–º LLM –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å
            merge_prompt = f"""–û–±—ä–µ–¥–∏–Ω–∏ —ç—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–∫—Ç—ã –≤ –û–î–ò–ù –∫—Ä–∞—Ç–∫–∏–π —Ñ–∞–∫—Ç:

    {merge_text}

    –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–º —Ñ–∞–∫—Ç–æ–º, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."""

            payload = {"model": llm_model, "prompt": merge_prompt, "stream": False}

            try:
                response = requests.post(llm_url, json=payload, timeout=20)
                if response.status_code == 200:
                    merged_fact = response.json().get("response", "").strip()

                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π, —É–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
                    self.update_memory(mem1['id'], merged_fact)
                    for dup in duplicates:
                        self.delete_memory(dup['id'])
                        processed_ids.add(dup['id'])

                    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–∏–ª {len(duplicates) + 1} –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π: {merged_fact[:50]}...")
                    processed_ids.add(mem1['id'])

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")



    def extract_with_llm_verified(self, user_message: str, assistant_response: str,
                                  llm_url: str, llm_model: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        """
        import requests
        import re

        extraction_prompt = f"""–¢—ã - —Å–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤. –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –∏–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ø–í–ù–û –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –¥–∏–∞–ª–æ–≥–µ.

    ‚õî –°–¢–†–û–ì–û –ó–ê–ü–†–ï–©–ï–ù–û:
    - –ü—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –ù–ï–¢ –≤ –¥–∏–∞–ª–æ–≥–µ
    - –î–æ–¥—É–º—ã–≤–∞—Ç—å –¥–µ—Ç–∞–ª–∏
    - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∫–∞–∫ —Ñ–∞–∫—Ç—ã

    ‚úÖ –†–ê–ó–†–ï–®–ï–ù–û –∏–∑–≤–ª–µ–∫–∞—Ç—å:
    - –ü—Ä—è–º—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ —Å–µ–±–µ ("—è —Ä–∞–±–æ—Ç–∞—é X", "–º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è Y")
    - –Ø–≤–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏ —Ñ–∞–∫—Ç—ã

    –î–ò–ê–õ–û–ì:
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}
    –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {assistant_response}

    –ó–ê–î–ê–ß–ê: –ò–∑–≤–ª–µ–∫–∏ 1-2 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–∞ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –ò–ó –≠–¢–û–ì–û –î–ò–ê–õ–û–ì–ê –∏–ª–∏ –Ω–∞–ø–∏—à–∏ "–ù–ò–ß–ï–ì–û" –µ—Å–ª–∏ —Ñ–∞–∫—Ç–æ–≤ –Ω–µ—Ç.

    –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏):
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω—Ä–∞–≤—è—Ç—Å—è –∫–æ—à–∫–∏"""

        payload = {
            "model": llm_model,
            "prompt": extraction_prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,
                "top_p": 0.9
            }
        }

        try:
            self.log("–ó–∞–ø—Ä–æ—Å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤ –∫ LLM...", "INFO")
            response = requests.post(llm_url, json=payload, timeout=30)

            if response.status_code == 200:
                result = response.json()
                facts_text = result.get("response", "").strip()

                self.log(f"LLM –æ—Ç–≤–µ—Ç–∏–ª: '{facts_text[:100]}...'", "INFO")

                if not facts_text or facts_text.upper() == "–ù–ò–ß–ï–ì–û" or "–ù–ò–ß–ï–ì–û" in facts_text.upper():
                    self.log("–§–∞–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã", "INFO")
                    return []

                facts = [f.strip() for f in facts_text.split('\n') if f.strip()]

                cleaned_facts = []
                for fact in facts:
                    fact = re.sub(r'^[\d\.\-\‚Ä¢\)\]\*\s]+', '', fact).strip()

                    if len(fact) > 10 and any(keyword in fact.lower() for keyword in
                                              ['–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª', '–ª—é–±–∏—Ç', '–Ω—Ä–∞–≤–∏—Ç—Å—è', '—Ä–∞–±–æ—Ç–∞–µ—Ç', '–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç', '–∂–∏–≤–µ—Ç',
                                               '–∑–∞–Ω–∏–º–∞–µ—Ç—Å—è', '—É–≤–ª–µ–∫–∞–µ—Ç—Å—è']):

                        user_words = set(user_message.lower().split())
                        fact_words = set(fact.lower().split())

                        common_words = user_words & fact_words - {'—è', '–º–Ω–µ', '–º–µ–Ω—è', '–º–æ–π', '–º–æ—è', '–º–æ—ë', '–º–æ–∏', '—ç—Ç–æ',
                                                                  '—á—Ç–æ', '–∏', '–≤', '–Ω–∞', '—Å', '–∫'}

                        if common_words or len(fact) < 50:
                            cleaned_facts.append(fact)
                            self.log(f"‚úì –í–∞–ª–∏–¥–Ω—ã–π —Ñ–∞–∫—Ç: '{fact}'", "SUCCESS")
                        else:
                            self.log(f"‚úó –ü–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—é: '{fact}'", "WARNING")
                    else:
                        self.log(f"‚úó –û—Ç–∫–ª–æ–Ω–µ–Ω: '{fact}'", "WARNING")

                return cleaned_facts[:2]

        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}", "ERROR")

        return []



    # ‚úÖ –î–û–ë–ê–í–¨ –≠–¢–û–¢ –ú–ï–¢–û–î –°–†–ê–ó–£ –ü–û–°–õ–ï __init__
    def log(self, message: str, level: str = "INFO"):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π –ø–∞–º—è—Ç–∏"""
        if self.debug_mode:
            emoji = {"INFO": "‚ÑπÔ∏è", "SUCCESS": "‚úÖ", "WARNING": "‚ö†Ô∏è", "ERROR": "‚ùå"}
            print(f"{emoji.get(level, '‚ÑπÔ∏è')} [MEMORY] {message}")