# voice_assistant.py
import json
import requests
import pyttsx3
import pyaudio
from vosk import Model, KaldiRecognizer
from core.plugin_loader import load_plugins, run_plugin
import threading
import queue

# üåê –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama
LLM_URL = "http://127.0.0.1:11434/api/generate"
LLM_MODEL = "gemma3:4b"

# üé§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
model = Model("E:\\python\\PYCHARM\\UZISpeach\\vosk-model-small-ru-0.22")
recognizer = KaldiRecognizer(model, 16000)

p = pyaudio.PyAudio()
stream = p.open(format=pyaudio.paInt16,
                channels=1,
                rate=16000,
                input=True,
                frames_per_buffer=4096)
stream.start_stream()

# ‚úÖ –†–ï–®–ï–ù–ò–ï: –û—á–µ—Ä–µ–¥—å –¥–ª—è –æ–∑–≤—É—á–∫–∏ + –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫
speech_queue = queue.Queue()


def speech_worker():
    """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –æ–∑–≤—É—á–∫–∏ - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TTS –≤–Ω—É—Ç—Ä–∏ –ø–æ—Ç–æ–∫–∞"""
    # ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º pyttsx3 –í–ù–£–¢–†–ò —Ä–∞–±–æ—á–µ–≥–æ –ø–æ—Ç–æ–∫–∞
    tts = pyttsx3.init()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–æ–ª–æ—Å–∞
    voices = tts.getProperty('voices')
    for voice in voices:
        if "irina" in voice.name.lower():
            tts.setProperty('voice', voice.id)
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–æ–ª–æ—Å: {voice.name}")
            break

    tts.setProperty('rate', 160)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏
    while True:
        text = speech_queue.get()
        if text is None:  # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            break
        tts.say(text)
        tts.runAndWait()
        speech_queue.task_done()


# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –æ–∑–≤—É—á–∫–∏
speech_thread = threading.Thread(target=speech_worker, daemon=True)
speech_thread.start()


def speak(text):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –æ—á–µ—Ä–µ–¥—å –æ–∑–≤—É—á–∫–∏ (–Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–µ)"""
    speech_queue.put(text)


# ‚úÖ –†–ï–®–ï–ù–ò–ï 2: –û—á–∏—Å—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞ –ø–µ—Ä–µ–¥ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ–º
def listen_command():
    """–ü—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã —Å –æ—á–∏—Å—Ç–∫–æ–π –±—É—Ñ–µ—Ä–∞"""
    print("üéôÔ∏è –ì–æ–≤–æ—Ä–∏ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º)...")

    # –û—á–∏—â–∞–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –±—É—Ñ–µ—Ä –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    try:
        stream.read(stream.get_read_available(), exception_on_overflow=False)
    except:
        pass

    while True:
        data = stream.read(4096, exception_on_overflow=False)
        if recognizer.AcceptWaveform(data):
            result = json.loads(recognizer.Result())
            text = result.get("text", "")
            if text:
                print(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")
                return text


chat_history = []  # üíæ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
use_stream = True
MAX_HISTORY = 20  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞


def query_llm_stream(user_input):
    chat_history.append(f"User: {user_input}")
    # –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ MAX_HISTORY —Å–æ–æ–±—â–µ–Ω–∏–π
    context = chat_history[-MAX_HISTORY:]
    full_prompt = "\n".join(context) + "\nAssistant:"

    payload = {
        "model": LLM_MODEL,
        "prompt": full_prompt
    }

    try:
        response = requests.post(LLM_URL, json=payload, stream=True)

        if response.status_code != 200:
            return f"–û—à–∏–±–∫–∞: {response.status_code} {response.text}"

        reply = ""
        print("üí¨ –û—Ç–≤–µ—Ç –ò–ò:", end=' ', flush=True)

        for line in response.iter_lines():
            if line:
                part = json.loads(line.decode('utf-8')).get("response", "")
                print(part, end='', flush=True)
                reply += part

        print()
        chat_history.append(f"Assistant: {reply}")
        return reply

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {str(e)}"


def main():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–ª–∞–≥–∏–Ω–æ–≤
    plugin_handlers = load_plugins()

    # –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    print("üß† –õ–æ–∫–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–Ω–∞ —Ä—É—Å—Å–∫–æ–º)")
    speak("–ü—Ä–∏–≤–µ—Ç, —Ö–æ–∑—è–∏–Ω!")

    while True:
        user_input = listen_command()
        if not user_input:
            continue

        if any(word in user_input for word in ["–≤—ã—Ö–æ–¥", "—Å—Ç–æ–ø", "–≤—ã–∫–ª—é—á–∏—Å—å", "–∑–∞–∫—Ä–æ–π—Å—è"]):
            speak("–ü–æ–∫–∞, —Ö–æ–∑—è–∏–Ω!")
            print("üëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            speech_queue.put(None)  # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –æ–∑–≤—É—á–∫–∏
            speech_thread.join(timeout=2)  # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–∑–≤—É—á–∫–∏
            break

        handled = False
        for handler in plugin_handlers:
            result = handler(user_input)
            if result:
                chat_history.append(f"Assistant: {result}")
                print("üß© –ü–ª–∞–≥–∏–Ω:", result)
                speak(result)
                handled = True
                break

        if not handled:
            reply = query_llm_stream(user_input)
            speak(reply)


if __name__ == "__main__":
    main()
